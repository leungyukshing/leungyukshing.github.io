---
title: 浅谈API网关
mathjax: true
abbrlink: 21270
date: 2021-08-06 00:27:43
tags:
---

# Introduction

&emsp;&emsp;今天我们来聊聊网关（Gateway）。在当下微服务架构的潮流下，网关是一个很重要的部分。在这篇博客，我们将一起了解网关的基本架构、功能等。

<!-- more -->

---

# Basis for Gateway

&emsp;&emsp;主流的网关需要具备什么基本的功能呢？

1. **反向代理**：反向代理指的是，对于客户端，屏蔽后端各个服务的细节，客户端只需要知道网关的域名，把请求达到网关即可，然后网关会把resp返回给客户端，至于网关后具体调用了什么微服务，客户端并不关心。因此对于后端来说，网关就是一个proxy；
2. **负载均衡**：后端的服务一般是多点部署的，网关能够把来自客户端的请求均衡地分配给不同的节点；
3. **身份、权限认证**：来自客户端的请求并不都是安全的、善良的，如果请求直接达到后端的服务中，很容易有安全攻击问题，因此网关需要对请求有一个基本的身份验证。其中包括仅允许可信客户端访问，或使用类似RBAC的方式来授权；
4. **IP黑白名单**：网关需具备允许或阻止某些IP通过的功能，比如直接拉黑某些危险的ip地址，或者对某些已经认证的ip地址加白；
5. **限流限频**：与第三点相类似，网关需要对背后的服务有一个基本的保障，所以需要对来自客户端的请求具有一定的限流、限频策略，减少对后面服务的压力；
6. **请求变形或转换**：网关具有路由转发的功能，在路由到后端服务前，网关有可能需要把来自前端的请求进行转换，可能是把header、body进行转换，甚至进行协议的转换，如把http请求转换为内部的协议；
7. **版本控制**：网关的升级最常见就是API发布，一般来说现在的API发布都需要灰度或者蓝绿部署，一个合格的网关需要具备这种功能；
8. **性能监控**：网关需要对整体的流量、每个API的流量、请求成功率、失败率等指标进行度量并统计，用于反馈给开发者优化系统；

---

# Mainstream Gateway

&emsp;&emsp;在这里我将简单介绍一些主流的网关，虽然在实际开发的过程中，很少直接套用某个网关，多多少少都需要有一些修改，但是还是很有必要了解一些基础的网关。

## Nginx

&emsp;&emsp;[Nginx](https://www.nginx.com/)是一款**轻量级的Web服务器**、**反向代理服务器**、**API网关**。它的功能有很多，但这里我们只关注它作为网关的基本信息。

### 工作模式

&emsp;&emsp;Nginx采用的是master-worker的工作模式，即存在主从节点。master节点的作用是读取并验证配置文件`nginx.conf`，同时管理所有的worker进程；而worker节点的作用是，每个节点维护一个线程，处理来自客户端的请求。worker的数量取决于配置文件`nginx.conf`的参数设置（一般来说worker的数量设置到和CPU核的数量一致即可）。

### 高并发

&emsp;&emsp;高并发绝对是网关必须具备的属性，因为用户的请求的最终目的是服务器的逻辑处理，但是如果网关成为瓶颈的话，就会使得请求的延时很高，影响用户体验，因此如何做到高并发一定是网关永恒的命题。

&emsp;&emsp;每个worker都有一个线程，如果worker使用同步、阻塞的方式去处理每一个请求，那么整个系统最高的并发度就是CPU核的数量。Nginx能做到高并发，其关键就是worker采用的是Linux的epoll模型。大致的思路是，当一个worker处理请求时，当遇到阻塞或同步事件后，它会生成一个监控事件，然后放入epoll队列中，紧接着就去处理第二个请求。当第一个请求完成后，会出发这个监控事件，然后worker就继续处理第一个请求。

&emsp;&emsp;举了例子，此时Nginx先处理请求A，对请求A进行权限校验等处理，然后把这个请求路由给后端服务，因为这里有一个同步等待，所以生成了一个监控事件，放入epoll队列中；然后Nginx就去处理请求B，以此类推。当请求A被后端服务处理完后，就会触发监控事件，然后Nginx重新处理请求A，进而返回给客户端。

&emsp;&emsp;采用单线程+epoll的方法好处是Nginx不需要为每个请求都分配CPU和内存资源，减少了许多上下文切换。

### 高可用

&emsp;&emsp;除了高并发外，高可用也是网关必备的属性。试想一下，如果网关出问题了，来自客户端所有的请求都将失败，那么对用户的影响将是灾难性的。所以网关一定不能单点部署，而需要通过集群部署的方式来实现高可用。

&emsp;&emsp;来自客户端的请求并不是直接打到网关集群上面，而是先打到一个VIP中，然后再把请求路由给可用的Nginx。

### 热部署

&emsp;&emsp;所谓热部署指的是修改了配置文件`nginx.conf`后，不需要重启服务就能让配置生效。可能有人会问，这有什么，重启一下又能怎样。但这个特性实际上是非常重要而且有用的。因为对于网关来说，肯定会部署非常多的节点，如果采用滚动升级的方式，重启一次所有的网关节点可能需要大量的时间，同时，重启时会有短时间的不可用。因此能做到热部署是最好的。

&emsp;&emsp;一般来说热部署的实现有两种方式。第一，在修改完配置文件后，master监听到修改的操作，然后把新的配置信息推送给worker，worker节点收到后，使用新的配置信息更新自己；第二，在修改完配置后，master使用新的配置重新生成新的worker，然后把新来的请求都交给新生成的worker来处理，对于旧的worker则不在分配请求，在它们处理完手上的请求后就杀掉。而Nginx采用的是**第二种方式**。

## Kong

&emsp;&emsp;Kong是一款基于Nginx和OpenResty的开源API网关，主要包含三个部分：

1. Nginx提供协议实现和工作进程管理；
2. OpenResty提供Lua集成并挂钩到Nginx的请求处理阶段；
3. 数据存储选择PostgreSQL或者Cassandra。

# Summary

&emsp;&emsp;当然现有的开源的API网关还有很多，我们在使用的时候通常也是基于某一款进行改造，务求达到自己的使用目的，但它们的基本功能都是相似的。相信通过这篇博客，大家对网关有了一个基本的认识，在以后的使用过程中也就心中有数。

------

# Reference

1. [开源API网关，到底哪个强](https://mp.weixin.qq.com/s/6W5Ze-CD6YxazyGcFlCRFA)
2. [一文搞懂蓝绿部署和金丝雀发布](https://segmentfault.com/a/1190000022448335)
3. [Linux IO模式及select、poll、epoll详解](https://segmentfault.com/a/1190000003063859)
4. [微服务API网关Kong实践](https://segmentfault.com/a/1190000022843318)
